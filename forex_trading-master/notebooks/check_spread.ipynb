{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pprint as pp\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "RE_FNAME = re.compile(r'LP\\-(?P<idx>[0-9])\\-STRM\\-[0-9]\\-(?P<pair>[A-Z]+).*\\.csv')\n",
    "\n",
    "from utils import GCStorage\n",
    "from constants import CREDENTIAL_PATH, ALL_DAYS\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import shutil\n",
    "import csv\n",
    "import numpy as np\n",
    "from subprocess import call\n",
    "import pickle\n",
    "\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import GCStorage\n",
    "from constants import *\n",
    "from multiprocessing import Pool, Manager, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = 60\n",
    "organized_path = TEMP_FOLDER / 'organized_data'\n",
    "\n",
    "jfolder = f'joint_{time_interval}_data'\n",
    "joint_path = TEMP_FOLDER / f'{jfolder}'\n",
    "joint_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "storage = GCStorage('FX_Trading', 'integral_data', CREDENTIAL_PATH)\n",
    "candle_interval = datetime.timedelta(seconds=time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_pairs = ['AUDUSD', 'EURUSD', 'GBPUSD', 'NZDUSD', 'USDCAD', 'USDCHF', 'USDJPY']\n",
    "# valid_pairs = ['AUDUSD']\n",
    "# valid_pairs = ['EURUSD']\n",
    "valid_pairs = ['NZDUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_pair_df(day, pair):\n",
    "    print(f'Checking {pair} {day}')\n",
    "    \n",
    "    lp_df = []\n",
    "    day = day.replace('-', '')\n",
    "    for lp in range(1, 6):\n",
    "        fname = TEMP_FOLDER / f'pickled_data/{pair}/{day}/{day}-{pair}-{lp}.pickle'\n",
    "        \n",
    "        df = pickle.load(open(fname, 'rb'))\n",
    "        \n",
    "        # Remove invalid rows\n",
    "        df = df[(df['ask price'] != 0) & (df['bid price'] != 0) & (df['ask volume'] != 0) & (df['bid volume'] != 0)]\n",
    "        \n",
    "        lp_df.append(df)\n",
    "        print(len(df))\n",
    "        \n",
    "    lp_index = [0, 0, 0, 0, 0]\n",
    "    times = [lp_df[i].iloc[lp_index[i]]['time'] for i in range(5)]\n",
    "    cur_max_time = np.max(times)\n",
    "    max_time_lp = np.argmax(times)\n",
    "    for lp in range(5):\n",
    "        while lp_df[lp].iloc[lp_index[lp]]['time'] < cur_max_time:\n",
    "            lp_index[lp] += 1\n",
    "    \n",
    "        if lp == max_time_lp:\n",
    "            lp_index[lp] += 1\n",
    "    \n",
    "    print(f'Starting time: {cur_max_time}')\n",
    "    return lp_df, lp_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_df, lp_index = get_daily_pair_df('2019-02-01', 'AUDUSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_time(lp_df, lp_index):\n",
    "    times = [lp_df[i].iloc[lp_index[i] - 1]['time'] for i in range(5)]\n",
    "    cur_max_time = np.max(times)\n",
    "    max_time_lp = np.argmax(times)\n",
    "    # print(f'Head Time (LP={max_time_lp}): {cur_max_time}')\n",
    "    # print(lp_index)\n",
    "    \n",
    "def direct_increment(args):\n",
    "    day_string, pair, lp_df, lp_index = args\n",
    "    print(f'Processing {pair} {day_string}')\n",
    "    # CAP each df\n",
    "    # lp_df = [df.iloc[:5 * 1000] for df in lp_df]\n",
    "    \n",
    "    lp_index = copy.copy(lp_index)\n",
    "    max_lens= [len(df) for df in lp_df]\n",
    "    print(max_lens)\n",
    "    \n",
    "    count = 0\n",
    "    inversions = []\n",
    "    inversion_status = {}\n",
    "\n",
    "    # while (True not in [lp_index[i] >= len(lp_df[i]) for i in range(5)]) and count < 10 * 1000:\n",
    "    while (True not in [lp_index[i] >= len(lp_df[i]) for i in range(5)]):\n",
    "    \n",
    "        get_head_time(lp_df, lp_index)\n",
    "        \n",
    "        cur_rows = [lp_df[lp].iloc[lp_index[lp] - 1] for lp in range(5)]\n",
    "        \n",
    "        cur_asks = [cur_rows[i]['ask price'] for i in range(5)]\n",
    "        cur_bids = [cur_rows[i]['bid price'] for i in range(5)]\n",
    "        cur_times = [cur_rows[i]['time'] for i in range(5)]\n",
    "        \n",
    "        cur_lowest_ask = round(np.min(cur_asks), 8)\n",
    "        cur_highest_bid = round(np.max(cur_bids), 8)\n",
    "\n",
    "        cur_lowest_ask_lp = np.argmin(cur_asks)\n",
    "        cur_highest_bid_lp = np.argmax(cur_bids)\n",
    "        \n",
    "        cur_lowest_ask_time = cur_rows[cur_lowest_ask_lp]['time']\n",
    "        cur_highest_bid_time = cur_rows[cur_highest_bid_lp]['time']\n",
    "        \n",
    "        all_inversions = list(inversion_status.keys())\n",
    "        for inversion in all_inversions:\n",
    "            cur_highest_bid_bid = cur_bids[inversion_status[inversion]['bid lp']]\n",
    "            cur_lowest_ask_ask = cur_bids[inversion_status[inversion]['ask lp']]\n",
    "            \n",
    "            if cur_highest_bid_bid > cur_lowest_ask_ask:\n",
    "                inversion_status[inversion]['last valid bid'] = cur_highest_bid_bid\n",
    "                inversion_status[inversion]['last valid bid time'] = cur_times[inversion_status[inversion]['bid lp']]\n",
    "                inversion_status[inversion]['last valid ask'] = cur_lowest_ask_ask\n",
    "                inversion_status[inversion]['last valid ask time'] = cur_times[inversion_status[inversion]['ask lp']]\n",
    "            else:\n",
    "                inversion_status[inversion]['exit bid'] = cur_highest_bid_bid\n",
    "                inversion_status[inversion]['exit bid time'] = cur_times[inversion_status[inversion]['bid lp']]\n",
    "                inversion_status[inversion]['exit ask'] = cur_lowest_ask_ask\n",
    "                inversion_status[inversion]['exit ask time'] = cur_times[inversion_status[inversion]['ask lp']]\n",
    "                \n",
    "                inversions.append(copy.deepcopy(inversion_status[inversion]))\n",
    "                del inversion_status[inversion]\n",
    "\n",
    "        if cur_highest_bid > cur_lowest_ask:\n",
    "\n",
    "            if (cur_highest_bid_lp, cur_lowest_ask_lp) not in inversion_status:\n",
    "            \n",
    "                diff = round((cur_highest_bid - cur_lowest_ask) * 10000, 1)\n",
    "                time_diff = round((cur_highest_bid_time - cur_lowest_ask_time).microseconds / 1000, 2)\n",
    "                if cur_highest_bid_time < cur_lowest_ask_time:\n",
    "                    time_diff = 1000 - time_diff\n",
    "\n",
    "                inversion_dict = {'time to occur': time_diff, 'price diff': diff,\n",
    "                                  'bid': cur_highest_bid, 'ask': cur_lowest_ask,\n",
    "                                  'bid time': cur_highest_bid_time, 'ask time': cur_lowest_ask_time,\n",
    "                                  'bid lp': cur_highest_bid_lp, 'ask lp': cur_lowest_ask_lp,\n",
    "                                  'last valid bid': cur_highest_bid, 'last valid ask': cur_lowest_ask,\n",
    "                                  'last valid bid time': cur_highest_bid_time, 'last valid ask time': cur_lowest_ask_time,\n",
    "                                  'exit bid': None, 'exit ask': None,\n",
    "                                  'exit bid time': None, 'exit ask time': None,\n",
    "                                 }\n",
    "                inversion_status[(cur_highest_bid_lp, cur_lowest_ask_lp)] = inversion_dict\n",
    "        \n",
    "        lowest_time = [lp_df[lp].iloc[lp_index[lp]]['time'] for lp in range(5)]\n",
    "        lowest_time_lp = np.argmin(lowest_time)\n",
    "        lp_index[lowest_time_lp] += 1\n",
    "\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            # print(count)\n",
    "            print(f'Progress for {day_string}: {lp_index}/{max_lens}')\n",
    "            \n",
    "        if count % 50000 == 0:\n",
    "            # print(count)\n",
    "            print(f'Temporarily storing {day_string}: {lp_index}/{max_lens}')\n",
    "            pickle.dump(inversions, open(f'inversions/{pair}/{pair}_{day_string}.pickle', 'wb'))\n",
    "\n",
    "    #for i, df in enumerate(lp_df):\n",
    "    #    print(df.iloc[:lp_index[i]][['time']])\n",
    "    print(f'Finished processing for {pair} {day_string}')\n",
    "    pickle.dump(inversions, open(f'inversions/{pair}/{pair}_{day_string}.pickle', 'wb'))\n",
    "    return inversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inversions = direct_increment('2019-02-01', lp_df, lp_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pair = 'NZDUSD'\n",
    "os.makedirs(f'inversions/{pair}', exist_ok=True)\n",
    "\n",
    "arguments = []\n",
    "for day in ALL_DAYS:\n",
    "    try:\n",
    "        lp_df, lp_index = get_daily_pair_df(day, pair)\n",
    "        arguments.append((day, pair, lp_df, lp_index))\n",
    "    except:\n",
    "        print(f'Unable to get {day}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl = Pool(len(ALL_DAYS))\n",
    "pl.map(direct_increment, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for inv in inversions:\n",
    "    \n",
    "    print('Diff', inv[\"price diff\"])\n",
    "    print(f'Starting spread: {round(inv[\"last valid bid\"], 8)} - {round(inv[\"last valid ask\"], 8)}')\n",
    "    print(f'Bid time: {inv[\"bid time\"]}')\n",
    "    print(f'Ask time: {inv[\"ask time\"]}')\n",
    "    \n",
    "    \n",
    "    #print(start_time)\n",
    "    \n",
    "    print('Last => Exit bid time', inv[\"last valid bid time\"], inv[\"exit bid time\"])\n",
    "    print('Last => Exit ask time', inv[\"last valid ask time\"], inv[\"exit ask time\"])\n",
    "          \n",
    "    start_time = max(inv[\"bid time\"], inv[\"ask time\"])\n",
    "    last_valid = min(inv[\"last valid bid time\"], inv[\"last valid ask time\"])\n",
    "    trading_window = int(round((last_valid - start_time).total_seconds() * 1000))\n",
    "        \n",
    "    #print(last_valid)\n",
    "    \n",
    "    print('Trading Window (Miliseconds)', trading_window, f'{start_time} - {last_valid}')\n",
    "    \n",
    "    \n",
    "    exit_time = min(inv[\"exit bid time\"], inv[\"exit ask time\"])\n",
    "    print(exit_time)\n",
    "    \n",
    "    \n",
    "    print('----')\n",
    "    #print(f'Dif: {inv[\"price diff\"]} pip\\t{t_diff} milisec')\n",
    "    #print(f'Bid: {inv[\"bid\"]}\\t{inv[\"bid time\"]}')\n",
    "    #print(f'Ask: {inv[\"ask\"]}\\t{inv[\"ask time\"]}')\n",
    "    #print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            #print(f'Dif: {diff} pip\\t{time_diff} milisec')\n",
    "            #print(f'Bid: {cur_highest_bet}\\t{cur_highest_bet_time}')\n",
    "            #print(f'Ask: {cur_lowest_ask}\\t{cur_lowest_ask_time}')\n",
    "            #print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_increment(day, pair):\n",
    "    print(f'Checking {pair} {day}')\n",
    "    \n",
    "    lp_df = []\n",
    "    day = day.replace('-', '')\n",
    "    for lp in range(1, 6):\n",
    "        fname = f'/sailhome/jingbo/CXR_RELATED/temp_store/pickled_data/{pair}/{day}/{day}-{pair}-{lp}.pickle'\n",
    "        \n",
    "        df = pickle.load(open(fname, 'rb'))\n",
    "        \n",
    "        # Remove invalid rows\n",
    "        df = df[(df['ask price'] != 0) & (df['bid price'] != 0) & (df['ask volume'] != 0) & (df['bid volume'] != 0)]\n",
    "        \n",
    "        lp_df.append(df)\n",
    "        print(len(df))\n",
    "        \n",
    "    lp_index = [0, 0, 0, 0, 0]\n",
    "    cur_max_time = max([lp_df[i].iloc[0]['time'] for i in range(5)])\n",
    "    \n",
    "    all_increments = []\n",
    "    count = 0\n",
    "    while (True not in [lp_index[i] >= len(lp_df[i]) for i in range(5)]) and count < 10 * 1000:\n",
    "        \n",
    "        for lp in range(5):\n",
    "            while lp_df[lp].iloc[lp_index[lp]]['time'] <= cur_max_time:\n",
    "                lp_index[lp] += 1\n",
    "            \n",
    "        # -1 to get the most recent (not the next)\n",
    "        cur_rows = [lp_df[i].iloc[lp_index[i] - 1] for i in range(5)]\n",
    "        all_increments.append(cur_rows)\n",
    "        \n",
    "        cur_max_time = max([lp_df[i].iloc[lp_index[i]]['time'] for i in range(5)])        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 250 == 0:\n",
    "            print(count)\n",
    "    \n",
    "    return all_increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "incremental_info = daily_increment('2019-02-01', 'AUDUSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_increments(increments):\n",
    "    for inc in increments:\n",
    "        \n",
    "        cur_asks = [inc[i]['ask price'] for i in range(5)]\n",
    "        cur_bids = [inc[i]['bid price'] for i in range(5)]\n",
    "        cur_times = [inc[i]['time'] for i in range(5)]\n",
    "\n",
    "        cur_lowest_ask = round(np.min(cur_asks), 8)\n",
    "        cur_highest_bet = round(np.max(cur_bids), 8)\n",
    "\n",
    "        cur_lowest_ask_lp = np.argmin(cur_asks)\n",
    "        cur_highest_bet_lp = np.argmax(cur_bids)\n",
    "\n",
    "        cur_lowest_ask_time = inc[cur_lowest_ask_lp]['time']\n",
    "        cur_highest_bet_time = inc[cur_highest_bet_lp]['time']\n",
    "        \n",
    "        if cur_highest_bet > cur_lowest_ask:\n",
    "            print(f'Higest Bet: {cur_highest_bet}\\tBet Time: {cur_highest_bet_time}')\n",
    "            print(f'Lowest Ask: {cur_lowest_ask}Bet Time: {cur_highest_bet_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_spread(spread_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_asks = [cur_rows[i]['ask price'] for i in range(5)]\n",
    "cur_bids = [cur_rows[i]['bid price'] for i in range(5)]\n",
    "cur_times = [cur_rows[i]['time'] for i in range(5)]\n",
    "\n",
    "cur_lowest_ask = np.min(cur_asks)\n",
    "cur_highest_bet = np.max(cur_bids)\n",
    "\n",
    "cur_lowest_ask_lp = np.argmin(cur_asks)\n",
    "cur_highest_bet_lp = np.argmax(cur_bids)\n",
    "\n",
    "cur_lowest_ask_time = cur_rows[cur_lowest_ask_lp]\n",
    "cur_highest_bet_time = np.argmax(cur_bids)\n",
    "\n",
    "all_spread.append([cur_max_time, cur_lowest_ask_lp, cur_highest_bet_lp, \\\n",
    "                   round(cur_lowest_ask, 8), round(cur_highest_bet, 8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in valid_pairs:\n",
    "    for day in ALL_DAYS:\n",
    "        check_day(pair, day)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
