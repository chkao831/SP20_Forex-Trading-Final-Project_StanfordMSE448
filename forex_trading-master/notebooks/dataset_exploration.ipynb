{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "\n",
    "from utils import GCStorage\n",
    "from constants import CREDENTIAL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = GCStorage('FX_Trading', 'integral_data', CREDENTIAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'raw_data': {'': {}, 'FX_Integral_data.zip': {}}},\n",
       " {'': {}, 'FX_Integral_data.zip': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.list_files('raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raw_data/FX_Integral_data.zip downloaded from bucket.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(os.environ['HOME'] + '/' + 'temp_store/raw_data', exist_ok=True)\n",
    "\n",
    "storage.download( os.environ['HOME'] + '/' + 'temp_store/raw_data/FX_Integral_data.zip', 'raw_data/FX_Integral_data.zip',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import pprint as pp\n",
    "\n",
    "from tqdm import tqdm\n",
    "RE_FNAME = re.compile(r'LP\\-(?P<idx>[0-9])\\-STRM\\-[0-9]\\-(?P<pair>[A-Z]+).*\\.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1290\n",
      "dict_keys(['EURUSD', 'NZDUSD', 'AUDUSD', 'GBPUSD', 'USDJPY', 'USDCAD', 'USDSEK', 'USDCHF'])\n"
     ]
    }
   ],
   "source": [
    "store = '/home/jingboyang/temp_store/raw_data/fx_integral_data'\n",
    "\n",
    "total_files = 0\n",
    "\n",
    "result_dict = defaultdict(list)\n",
    "\n",
    "for folder in os.listdir(store):\n",
    "    if '.zip' not in folder:\n",
    "        for f in os.listdir(f'{store}/{folder}'):\n",
    "            full_path = f'{store}/{folder}/{f}'\n",
    "            \n",
    "            total_files += 1\n",
    "            \n",
    "            result = RE_FNAME.search(f)\n",
    "            gd = result.groupdict()\n",
    "            \n",
    "            lp_idx = gd['idx']\n",
    "            pair = gd['pair']\n",
    "            \n",
    "            # print(pair, lp_idx)\n",
    "            result_dict[pair].append((lp_idx, full_path))\n",
    "            \n",
    "\n",
    "print(total_files)\n",
    "\n",
    "# pp.pprint(result_dict)\n",
    "print(result_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import shutil\n",
    "import csv\n",
    "import numpy as np\n",
    "from subprocess import call\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = Path('/home/jingboyang/temp_store/raw_data/fx_integral_data')\n",
    "new_path = Path('/home/jingboyang/temp_store/raw_data/organized_data')\n",
    "\n",
    "new_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:00<00:00, 6656.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDCHF\n",
      "None: 0\n",
      "2019-02-01 00:00:00: 15\n",
      "2019-02-03 00:00:00: 5\n",
      "2019-02-04 00:00:00: 5\n",
      "2019-02-05 00:00:00: 5\n",
      "2019-02-06 00:00:00: 5\n",
      "2019-02-07 00:00:00: 5\n",
      "2019-02-08 00:00:00: 5\n",
      "2019-02-10 00:00:00: 5\n",
      "2019-02-11 00:00:00: 5\n",
      "2019-02-12 00:00:00: 5\n",
      "2019-02-13 00:00:00: 5\n",
      "2019-02-14 00:00:00: 5\n",
      "2019-02-15 00:00:00: 5\n",
      "2019-02-17 00:00:00: 5\n",
      "2019-02-18 00:00:00: 5\n",
      "2019-02-19 00:00:00: 5\n",
      "2019-02-20 00:00:00: 5\n",
      "2019-02-21 00:00:00: 5\n",
      "2019-02-22 00:00:00: 5\n",
      "2019-02-24 00:00:00: 5\n",
      "2019-02-25 00:00:00: 5\n",
      "2019-02-26 00:00:00: 5\n",
      "2019-02-27 00:00:00: 5\n",
      "2019-02-28 00:00:00: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:09<00:00, 17.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDSEK\n",
      "None: 0\n",
      "2019-01-07 00:00:00: 2\n",
      "2019-01-08 00:00:00: 2\n",
      "2019-01-09 00:00:00: 2\n",
      "2019-01-10 00:00:00: 2\n",
      "2019-01-11 00:00:00: 2\n",
      "2019-02-01 00:00:00: 13\n",
      "2019-02-03 00:00:00: 4\n",
      "2019-02-04 00:00:00: 5\n",
      "2019-02-05 00:00:00: 5\n",
      "2019-02-06 00:00:00: 5\n",
      "2019-02-07 00:00:00: 5\n",
      "2019-02-08 00:00:00: 5\n",
      "2019-02-10 00:00:00: 4\n",
      "2019-02-11 00:00:00: 5\n",
      "2019-02-12 00:00:00: 5\n",
      "2019-02-13 00:00:00: 5\n",
      "2019-02-14 00:00:00: 5\n",
      "2019-02-15 00:00:00: 5\n",
      "2019-02-17 00:00:00: 4\n",
      "2019-02-18 00:00:00: 5\n",
      "2019-02-19 00:00:00: 5\n",
      "2019-02-20 00:00:00: 5\n",
      "2019-02-21 00:00:00: 5\n",
      "2019-02-22 00:00:00: 5\n",
      "2019-02-24 00:00:00: 4\n",
      "2019-02-25 00:00:00: 5\n",
      "2019-02-26 00:00:00: 5\n",
      "2019-02-27 00:00:00: 5\n",
      "2019-02-28 00:00:00: 5\n"
     ]
    }
   ],
   "source": [
    "# for pair in result_dict:\n",
    "#    print(pair)\n",
    "for pair in ['USDCHF', 'USDSEK']:\n",
    "    pair_path = new_path / pair\n",
    "    \n",
    "    organized = []\n",
    "    \n",
    "    for lp_idx, fpath in tqdm(result_dict[pair]):\n",
    "        \n",
    "        start_time_text = None\n",
    "        with open(fpath, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                # print(row['first_name'], row['last_name'])\n",
    "                start_time_text = row['time']\n",
    "                break\n",
    "        \n",
    "        if start_time_text is not None:\n",
    "\n",
    "            start_time = parse(start_time_text, dayfirst=False)\n",
    "            file_date = start_time.replace(minute=0, hour=0, second=0, microsecond=0)\n",
    "            # end_time = parse(df['time'][len(df) - 1], dayfirst=False)\n",
    "\n",
    "            folder = fpath.split('/')[-2]\n",
    "            fname = fpath.split('/')[-1]\n",
    "\n",
    "            fsize = os.path.getsize(fpath)\n",
    "\n",
    "            # organized.append((start_time, end_time, folder, fname))\n",
    "            organized.append({'file_date': file_date, 'lp_idx': lp_idx, 'pair': pair,\n",
    "                              'start_time': start_time, # 'end_date': end_time,\n",
    "                              'folder': folder, 'fpath': fpath, 'fname': fname,\n",
    "                              'data_length': fsize})\n",
    "                # print(f\"{df['time'][0]} {fpath[-80:]}\")\n",
    "            # except:\n",
    "            #     print(f'Unable to process: {fpath}')\n",
    "\n",
    "    \n",
    "    organized = sorted(organized, key=lambda x: (x['file_date'], x['lp_idx'], x['data_length']))\n",
    "    \n",
    "    prev_date = None\n",
    "    cur_path = None\n",
    "    counter = 0\n",
    "    print(pair)\n",
    "    for item in organized:\n",
    "        # print(f'{item[\"file_date\"]}: {item[\"lp_idx\"]}')\n",
    "        nice_date = item['file_date'].strftime(\"%Y%m%d\")\n",
    "        if item['file_date'] != prev_date:\n",
    "            print(f'{prev_date}: {counter}')\n",
    "            cur_path = pair_path / nice_date\n",
    "            cur_path.mkdir(parents=True, exist_ok=True)\n",
    "            counter = 0\n",
    "\n",
    "        counter += 1\n",
    "        new_fname = f'{nice_date}-{item[\"pair\"]}-{item[\"lp_idx\"]}.csv'\n",
    "        # shutil.copyfile(item['fpath'], cur_path / new_fname)\n",
    "        \n",
    "        call(['cp', str(item['fpath']), str(cur_path / new_fname)])\n",
    "\n",
    "        prev_date = item['file_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Moving stuff back to storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NZDUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [03:03<00:00,  7.33s/it]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDSEK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:06<00:00,  4.22s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDCHF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [03:16<00:00,  7.87s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [04:00<00:00,  9.62s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDCAD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [03:55<00:00,  9.41s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EURUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [05:11<00:00, 12.46s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDJPY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [04:54<00:00, 11.77s/it]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBPUSD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [06:37<00:00, 15.91s/it]\n"
     ]
    }
   ],
   "source": [
    "for pair in os.listdir(str(new_path)):\n",
    "    print(pair)\n",
    "    for date in tqdm(os.listdir(str(new_path / pair))):\n",
    "        for fname in os.listdir(str(new_path / pair / date)):\n",
    "            fpath = new_path / pair / date / fname\n",
    "\n",
    "            cloud_path = Path('organized_data') / pair / date / fname\n",
    "\n",
    "            storage.upload(fpath, cloud_path)\n",
    "\n",
    "            # break\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
